{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "Machine learning competitions are a great way to improve your data science skills and measure your progress. \n",
    "\n",
    "In this exercise, you will create and submit predictions for a Kaggle competition. You can then improve your model (e.g. by adding features) to improve and see how you stack up to others taking this micro-course.\n",
    "\n",
    "The steps in this notebook are:\n",
    "1. Build a Random Forest model with all of your data (**X** and **y**)\n",
    "2. Read in the \"test\" data, which doesn't include values for the target.  Predict home values in the test data with your Random Forest model.\n",
    "3. Submit those predictions to the competition and see your score.\n",
    "4. Optionally, come back to see if you can improve your model by adding features or changing your model. Then you can resubmit to see how that stacks up on the competition leaderboard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recap\n",
    "Here's the code you've written so far. Start by running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE when not specifying max_leaf_nodes: 29,653\n",
      "Validation MAE for best value of max_leaf_nodes: 27,283\n",
      "Validation MAE for Random Forest Model: 22,762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Code you have previously used to load data\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#from learntools.core import *\n",
    "\n",
    "\n",
    "\n",
    "# Path of the file to read. We changed the directory structure to simplify submitting to a competition\n",
    "iowa_file_path = 'F:\\\\ML App\\\\app\\\\Dataset\\\\train.csv'\n",
    "\n",
    "home_data = pd.read_csv(iowa_file_path)\n",
    "# Create target object and call it y\n",
    "y = home_data.SalePrice\n",
    "# Create X\n",
    "features = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']\n",
    "X = home_data[features]\n",
    "\n",
    "# Split into validation and training data\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "\n",
    "# Specify Model\n",
    "iowa_model = DecisionTreeRegressor(random_state=1)\n",
    "# Fit Model\n",
    "iowa_model.fit(train_X, train_y)\n",
    "\n",
    "# Make validation predictions and calculate mean absolute error\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE when not specifying max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Using best value for max_leaf_nodes\n",
    "iowa_model = DecisionTreeRegressor(max_leaf_nodes=100, random_state=1)\n",
    "iowa_model.fit(train_X, train_y)\n",
    "val_predictions = iowa_model.predict(val_X)\n",
    "val_mae = mean_absolute_error(val_predictions, val_y)\n",
    "print(\"Validation MAE for best value of max_leaf_nodes: {:,.0f}\".format(val_mae))\n",
    "\n",
    "# Define the model. Set random_state to 1\n",
    "rf_model = RandomForestRegressor(random_state=1)\n",
    "rf_model.fit(train_X, train_y)\n",
    "rf_val_predictions = rf_model.predict(val_X)\n",
    "rf_val_mae = mean_absolute_error(rf_val_predictions, val_y)\n",
    "\n",
    "print(\"Validation MAE for Random Forest Model: {:,.0f}\".format(rf_val_mae))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LotArea         10084\n",
      "YearBuilt        2004\n",
      "1stFlrSF         1694\n",
      "2ndFlrSF            0\n",
      "FullBath            2\n",
      "BedroomAbvGr        3\n",
      "TotRmsAbvGrd        7\n",
      "Name: 6, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.iloc[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307000\n"
     ]
    }
   ],
   "source": [
    "print(y.iloc[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Model For the Competition\n",
    "\n",
    "Build a Random Forest model and train it on all of **X** and **y**.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=1, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To improve accuracy, create a new Random Forest model which you will train on all training data\n",
    "rf_model_on_full_data = RandomForestRegressor(random_state=1)\n",
    "\n",
    "# fit rf_model_on_full_data on all data from the training data\n",
    "rf_model_on_full_data.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "Read the file of \"test\" data. And apply your model to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to file you will use for predictions\n",
    "test_data_path = 'F:\\\\ML App\\\\app\\\\Dataset\\\\test.csv'\n",
    "\n",
    "# read test data file using pandas\n",
    "test_data = pd.read_csv(test_data_path)\n",
    "\n",
    "# create test_X which comes from test_data but includes only the columns you used for prediction.\n",
    "# The list of columns is stored in a variable called features\n",
    "test_X = test_data[features]\n",
    "\n",
    "# make predictions which we will submit. \n",
    "test_preds = rf_model_on_full_data.predict(test_X)\n",
    "\n",
    "# The lines below shows how to save predictions in format used for competition scoring\n",
    "# Just uncomment them.\n",
    "\n",
    "output = pd.DataFrame({'Id': test_data.Id,\n",
    "                       'SalePrice': test_preds})\n",
    "output.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model_on_full_data, \"model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "6       10084       2004      1694         0         2             3   \n",
      "807     21384       1923      1072       504         1             3   \n",
      "955      7136       1946       979       979         2             4   \n",
      "1040    13125       1957      1803         0         2             3   \n",
      "701      9600       1969      1164         0         1             3   \n",
      "303      9800       1972       894         0         1             3   \n",
      "1264     4060       1998      1337         0         2             2   \n",
      "216      8450       2004      1436         0         2             3   \n",
      "1157     5001       2007      1314         0         2             2   \n",
      "350      7820       2007      1869         0         2             2   \n",
      "1350    11643       1969      1338      1296         2             6   \n",
      "1086     1974       1973       546       546         1             3   \n",
      "202      7000       1924       865       445         2             2   \n",
      "1192     9600       1925       842       630         1             3   \n",
      "527     14948       2008      1476      1237         2             3   \n",
      "310      7685       1993       697       804         2             3   \n",
      "916      9000       1949       480         0         0             1   \n",
      "1437    12444       2008      1932         0         2             2   \n",
      "8        6120       1931      1022       752         2             2   \n",
      "241      3880       1945       866         0         1             2   \n",
      "983     11250       2002      1149      1141         2             4   \n",
      "623      2117       2000       756       756         2             2   \n",
      "1267    13214       2008      2018         0         2             3   \n",
      "1393    10800       1905      1221       691         2             3   \n",
      "494      5784       1938       886         0         1             2   \n",
      "774     14226       2006      1973         0         2             3   \n",
      "997     11717       1970      1442         0         2             2   \n",
      "731      9590       2003      1146         0         2             3   \n",
      "864      8640       2007      1372         0         2             3   \n",
      "275      7264       1925       952       596         2             3   \n",
      "...       ...        ...       ...       ...       ...           ...   \n",
      "141     11645       2005      1734         0         2             3   \n",
      "1110     8000       1995       773       885         2             3   \n",
      "753     10240       2005      1038      1060         2             3   \n",
      "1001     5400       1920       691         0         1             2   \n",
      "1239     9037       2006      1484         0         2             2   \n",
      "580     14585       1960      1429         0         1             3   \n",
      "562     13907       1940       996         0         1             3   \n",
      "398      8967       1920      1077         0         1             2   \n",
      "668     14175       1956      1437         0         1             3   \n",
      "252      8366       2004       798       842         2             3   \n",
      "907     11500       1936      1020      1037         1             3   \n",
      "468     11428       2006      1634         0         2             3   \n",
      "914      3000       2009       612       612         2             2   \n",
      "357      4224       1976      1142         0         1             3   \n",
      "1278     9473       2002      1128       903         2             3   \n",
      "1300    10762       1999      1005       978         2             3   \n",
      "1202     6000       1925       884       464         1             3   \n",
      "1305    13173       2006      1652         0         2             2   \n",
      "1414    13053       1923      1053       795         1             4   \n",
      "508      9600       1928       689       689         2             3   \n",
      "749      8405       1945      1088       441         2             4   \n",
      "129      8973       1958      1053         0         1             3   \n",
      "144      9100       1963      1728         0         2             6   \n",
      "960      7207       1958       858         0         1             2   \n",
      "847     15523       1972       864         0         1             3   \n",
      "715     10140       1974      1350         0         2             3   \n",
      "905      9920       1954      1063         0         1             3   \n",
      "1096     6882       1914       773       582         1             3   \n",
      "235      1680       1971       483       504         1             2   \n",
      "1061    18000       1935       894         0         1             2   \n",
      "\n",
      "      TotRmsAbvGrd  \n",
      "6                7  \n",
      "807              6  \n",
      "955              8  \n",
      "1040             8  \n",
      "701              6  \n",
      "303              5  \n",
      "1264             5  \n",
      "216              8  \n",
      "1157             6  \n",
      "350              6  \n",
      "1350            12  \n",
      "1086             6  \n",
      "202              6  \n",
      "1192             6  \n",
      "527             11  \n",
      "310              6  \n",
      "916              4  \n",
      "1437             7  \n",
      "8                8  \n",
      "241              4  \n",
      "983              9  \n",
      "623              4  \n",
      "1267            10  \n",
      "1393             7  \n",
      "494              4  \n",
      "774              9  \n",
      "997              6  \n",
      "731              6  \n",
      "864              6  \n",
      "275              5  \n",
      "...            ...  \n",
      "141              7  \n",
      "1110             8  \n",
      "753              8  \n",
      "1001             4  \n",
      "1239             6  \n",
      "580              7  \n",
      "562              6  \n",
      "398              6  \n",
      "668              6  \n",
      "252              6  \n",
      "907              6  \n",
      "468              7  \n",
      "914              4  \n",
      "357              6  \n",
      "1278             7  \n",
      "1300             9  \n",
      "1202             5  \n",
      "1305             6  \n",
      "1414             8  \n",
      "508              7  \n",
      "749              9  \n",
      "129              6  \n",
      "144             10  \n",
      "960              4  \n",
      "847              5  \n",
      "715              7  \n",
      "905              6  \n",
      "1096             7  \n",
      "235              5  \n",
      "1061             6  \n",
      "\n",
      "[1095 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6       307000\n",
      "807     223500\n",
      "955     145000\n",
      "1040    155000\n",
      "701     140000\n",
      "303     149900\n",
      "1264    181000\n",
      "216     210000\n",
      "1157    230000\n",
      "350     318061\n",
      "1350    200000\n",
      "1086     83500\n",
      "202     112000\n",
      "1192    125000\n",
      "527     446261\n",
      "310     165600\n",
      "916      35311\n",
      "1437    394617\n",
      "8       129900\n",
      "241     110500\n",
      "983     255900\n",
      "623     168500\n",
      "1267    378500\n",
      "1393    163000\n",
      "494      91300\n",
      "774     395000\n",
      "997     185000\n",
      "731     187500\n",
      "864     250580\n",
      "275     205000\n",
      "         ...  \n",
      "141     260000\n",
      "1110    188000\n",
      "753     275500\n",
      "1001     86000\n",
      "1239    265900\n",
      "580     181900\n",
      "562     108000\n",
      "398      67000\n",
      "668     168000\n",
      "252     173000\n",
      "907     250000\n",
      "468     250000\n",
      "914     173733\n",
      "357     134000\n",
      "1278    237000\n",
      "1300    225000\n",
      "1202    117000\n",
      "1305    325000\n",
      "1414    207000\n",
      "508     161000\n",
      "749      98000\n",
      "129     150000\n",
      "144     125000\n",
      "960     116500\n",
      "847     133500\n",
      "715     165000\n",
      "905     128000\n",
      "1096    127000\n",
      "235      89500\n",
      "1061     81000\n",
      "Name: SalePrice, Length: 1095, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_X.iloc[:1,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "6    10084       2004      1694         0         2             3   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "6             7  \n"
     ]
    }
   ],
   "source": [
    "print(train_X.iloc[:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([6], dtype='int64')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.iloc[:1,:].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = train_X.iloc[:1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   LotArea  YearBuilt  1stFlrSF  2ndFlrSF  FullBath  BedroomAbvGr  \\\n",
      "6    10084       2004      1694         0         2             3   \n",
      "\n",
      "   TotRmsAbvGrd  \n",
      "6             7  \n"
     ]
    }
   ],
   "source": [
    "print(sample_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sample_data.pkl']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sample_data, \"sample_data.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Your Work\n",
    "After filling in the code above:\n",
    "1. Click the **Commit** button. \n",
    "2. After your code has finished running, click the \"Open Version\" button.  This brings you into the \"viewer mode\" for your notebook. You will need to scroll down to get back to these instructions.\n",
    "3. Click **Output** button on the left of your screen. \n",
    "\n",
    "This will bring you to a part of the screen that looks like this: \n",
    "![](https://imgur.com/a/QRHL7Uv)\n",
    "\n",
    "Select the button to submit and you will see your score. You have now successfully submitted to the competition.\n",
    "\n",
    "4. If you want to keep working to improve your model, select the edit button. Then you can change your model and repeat the process to submit again. There's a lot of room to improve your model, and you will climb up the leaderboard as you work.\n",
    "\n",
    "# Continuing Your Progress\n",
    "There are many ways to improve your model, and **experimenting is a great way to learn at this point.**\n",
    "\n",
    "The best way to improve your model is to add features.  Look at the list of columns and think about what might affect home prices.  Some features will cause errors because of issues like missing values or non-numeric data types. \n",
    "\n",
    "The [Intermediate Machine Learning](https://www.kaggle.com/learn/intermediate-machine-learning) micro-course will teach you how to handle these types of features. You will also learn to use **xgboost**, a technique giving even better accuracy than Random Forest.\n",
    "\n",
    "\n",
    "# Other Micro-Courses\n",
    "The **[Pandas Micro-Course](https://kaggle.com/Learn/Pandas)** will give you the data manipulation skills to quickly go from conceptual idea to implementation in your data science projects. \n",
    "\n",
    "You are also ready for the **[Deep Learning](https://kaggle.com/Learn/Deep-Learning)** micro-course, where you will build models with better-than-human level performance at computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**[Machine Learning Home Page](https://www.kaggle.com/learn/intro-to-machine-learning)**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*Have questions or comments? Visit the [Learn Discussion forum](https://www.kaggle.com/learn-forum) to chat with other Learners.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
